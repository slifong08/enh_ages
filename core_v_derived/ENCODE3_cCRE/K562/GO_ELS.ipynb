{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c592b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T23:42:30.628945Z",
     "start_time": "2021-12-23T23:42:29.747753Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import subprocess\n",
    "\n",
    "#%%\n",
    "\n",
    "PATH = \"/dors/capra_lab/projects/enhancer_ages/landscape/results/cCRE_x_tfbs_encode3/K562/data/\"\n",
    "\n",
    "CL = \"ELS_combined_K562\"\n",
    "BUILD = \"hg38\"\n",
    "MIN_GENES = 5 # min genes in group\n",
    "\n",
    "# possible pairwise comparisons to run GO annotation enrichment on.\n",
    "ANALYSIS_list = [\"der_v_core\", \"der_v_bkgd\", \"simple_v_core\", \"core_v_bkgd\", \"simple_v_bkgd\"]\n",
    "\n",
    "ANALYSIS = ANALYSIS_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b62278e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T23:42:33.851863Z",
     "start_time": "2021-12-23T23:42:33.799099Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% Functions\n",
    "\n",
    "# load GO dataframe\n",
    "def load_GO():\n",
    "\n",
    "\n",
    "    GOPATH = \"/dors/capra_lab/data/gene_ontology/\"\n",
    "    GOHU = f\"{GOPATH}goa_human.tsv\"\n",
    "    GOSLIM = f\"{GOPATH}PANTHERGOslim_gene_annot.tsv\"\n",
    "\n",
    "    go_ = pd.read_csv(GOHU, sep = '\\t')\n",
    "\n",
    "    #Reduce the go annotation dataframe to key elements\n",
    "    go = go_[[\"DB_Object_Symbol\", \"name\", \"namespace\",\n",
    "    \"Taxon\", \"GO_ID\", \"Aspect\"]].drop_duplicates()\n",
    "\n",
    "    return go_, go\n",
    "\n",
    "# load the cell line TF enrichment file_name\n",
    "def get_f_dict(cl):\n",
    "\n",
    "    cl_name = cl.split(\"ELS_combined_\")[1]\n",
    "\n",
    "    F_DICT = {\n",
    "    \"core_v_bkgd\" : f\"{cl_name}_core_v_bkgdOR_per_MRCA.tsv\",\n",
    "    \"der_v_bkgd\":f\"{cl_name}_der_v_bkgdOR_per_MRCA.tsv\",\n",
    "    \"der_v_core\":f\"{cl_name}_der_v_coreOR_per_MRCA.tsv\",\n",
    "    \"simple_v_bkgd\": f\"{cl_name}_simple_v_bkgdOR_per_MRCA.tsv\",\n",
    "    \"simple_v_core\":f\"{cl_name}_simple_v_coreOR_per_MRCA.tsv\",\n",
    "    \"simple_v_der\":f\"{cl_name}_simple_v_derOR_per_MRCA.tsv\"\n",
    "    }\n",
    "\n",
    "    return F_DICT\n",
    "\n",
    "# get the cell line TF enrichment dataframe\n",
    "def get_df(path, fdict_key):\n",
    "    F = os.path.join(path, fdict_key) # join the path\n",
    "    df = pd.read_csv(F, sep = '\\t')\n",
    "    return df\n",
    "\n",
    "# perform an FDR correction\n",
    "def fdr_correction(collection_dict, alpha):\n",
    "\n",
    "    df = pd.concat(collection_dict.values()) # concat the dictionary into a df\n",
    "\n",
    "    pvals = df[\"P\"] # get a vector of pvals from df\n",
    "\n",
    "    # run the multitest\n",
    "    df[\"reject_null\"], df[\"FDR_P\"] = statsmodels.stats.multitest.fdrcorrection(pvals, alpha=alpha)\n",
    "\n",
    "    return df\n",
    "\n",
    "# get the GO ids linked to TF genes\n",
    "# filter GO ids to:\n",
    "#(1) TF, (2) specific process, and (3) GO id gene group >=  min_genes\n",
    "\n",
    "def get_GO_IDs(tf_ids, df, go, process, min_genes_in_group):\n",
    "\n",
    "\n",
    "    # (1) get the go ids linked to enriched TFs and (2) process\n",
    "    tf_go = go.loc[(go.DB_Object_Symbol.isin(tf_ids)) &(go.Aspect == process)].drop_duplicates()\n",
    "\n",
    "    # count how many genes are in GO annotation related to TF\n",
    "    names = tf_go.groupby([\"Aspect\", \"name\", \"GO_ID\"])[\"Taxon\"].count().reset_index()\n",
    "\n",
    "    # (3) filter to GO groups with more than 3 TF genes in the group\n",
    "    names = names.loc[names.Taxon > min_genes_in_group]\n",
    "\n",
    "    return names, tf_go\n",
    "\n",
    "# get the TF genes that are enriched in comp1\n",
    "def get_tf_ids(comp1, df):\n",
    "\n",
    "    # get only sig values\n",
    "    sig = df.loc[df.reject_null == True].drop_duplicates()\n",
    "    # make a table of log2 values per age\n",
    "    summed_log2 = pd.pivot(sig, index = \"tf\", columns = \"mrca_2\", values = \"log2\").sum(axis = 1)\n",
    "\n",
    "    # drop the na, and reset the index\n",
    "    summed_log2 = summed_log2.dropna().reset_index()\n",
    "\n",
    "    # log2 > 0 = enriched in comp1\n",
    "    # GT = \"Greater Than\"\n",
    "    GTzero = summed_log2.loc[summed_log2[0]>0, \"tf\"].to_list()\n",
    "\n",
    "    # log2 < 0 = enriched in comp2\n",
    "    # LT = \"Lesser Than\"\n",
    "    LTzero = summed_log2.loc[summed_log2[0]<0, \"tf\"].to_list()\n",
    "\n",
    "    print(comp1, GTzero, len(GTzero))\n",
    "\n",
    "    return GTzero, LTzero\n",
    "\n",
    "def get_OR_go(comp1, comp2, df, process, min_genes_in_group):\n",
    "\n",
    "    # make a name for this analysis\n",
    "    comparison_name = f\"{comp1}_v_{comp2}_{process}\"\n",
    "\n",
    "    # get the list of tfs for the comparison\n",
    "    comp1_tf, comp2_tf = get_tf_ids(comp1, df)\n",
    "\n",
    "    # get TF genes, GO annotations associated with comp1\n",
    "    comp1_go_ids, comp1df, = get_GO_IDs(comp1_tf, df, go, process, min_genes_in_group)\n",
    "\n",
    "    # get TF genes, GO annotations associated with comp2\n",
    "    comp2_go_ids, comp2df, = get_GO_IDs(comp2_tf, df, go, process, min_genes_in_group)\n",
    "\n",
    "    # combine the genes enriched in comp1 and comp2\n",
    "    test_ids = pd.concat([comp1_go_ids, comp2_go_ids]) # concat arch1 and arch2 ids\n",
    "\n",
    "    # only run tests if there are annotations to run in the first comparison\n",
    "    if len(comp1_go_ids)>0:\n",
    "\n",
    "        collection_dict = {} # collect the OR results per GO ID\n",
    "\n",
    "        for goid in test_ids.GO_ID.unique():\n",
    "\n",
    "            test = comp1df.loc[comp1df.GO_ID == goid].drop_duplicates() # get df overlapping go term\n",
    "            test_genes = list(test.DB_Object_Symbol.unique()) # get the genes that overlap the term in test.\n",
    "            test_obs = test.shape[0] # count the number of genes overlapping go term in test\n",
    "            test_all = len(comp1df.DB_Object_Symbol.unique()) - test_obs # count total number of genes # w/o overlap?\n",
    "\n",
    "\n",
    "            bkgd_test = comp2df.loc[~comp2df.DB_Object_Symbol.isin(test_genes)] # subtract genes that are in test set, don't want to test them twice.\n",
    "            bkgd_test = bkgd_test[bkgd_test.GO_ID == goid].drop_duplicates() # count number of genes that overlap go term\n",
    "\n",
    "            bkgd_test_genes = list(bkgd_test.DB_Object_Symbol.unique()) # get the genes that overlap the term in test.\n",
    "            bkgd_overlap = bkgd_test.shape[0]\n",
    "            bkgd_all = len(comp2df.DB_Object_Symbol.unique()) - bkgd_overlap# count total number of genes # exlude test set?\n",
    "\n",
    "            obs = [[test_obs,test_all], [bkgd_overlap,bkgd_all]]\n",
    "            print(obs)\n",
    "            OR, P = stats.fisher_exact(obs)\n",
    "            #table = sm.stats.Table2x2(obs) # get confidence interval\n",
    "            #odds_ci = table.oddsratio_confint()\n",
    "\n",
    "\n",
    "            newdf = pd.DataFrame({\"comparison_name\":comparison_name,\n",
    "                                  \"a\":obs[0][0], \"b\":obs[0][1],\n",
    "                                  \"c\":obs[1][0], \"d\":obs[1][1],\n",
    "                                  \"OR\":[OR], \"P\":[P],\n",
    "                                  #\"ci_lower\" :[odds_ci[0]],\n",
    "                                  #\"ci_upper\" :[odds_ci[1]],\n",
    "                                  \"GO_ID\": goid\n",
    "                                })\n",
    "\n",
    "            collection_dict[goid] = newdf\n",
    "\n",
    "        if len(collection_dict.keys())>0:\n",
    "            alpha = 0.1\n",
    "            resultsdf = fdr_correction(collection_dict, alpha)\n",
    "            return resultsdf\n",
    "        else:\n",
    "            print(\"no GO annotation enrichment for\", comparison_name, process)\n",
    "    else:\n",
    "        print(\"no GO annotations for\", comparison_name, process)\n",
    "\n",
    "def get_annot(resultsdf, go):\n",
    "\n",
    "    sig_ids = resultsdf.loc[resultsdf.reject_null == True, \"GO_ID\"] # list of significant ids\n",
    "\n",
    "    annots_der = go.loc[go.GO_ID.isin(sig_ids), [\"GO_ID\",\"name\"]].drop_duplicates()\n",
    "\n",
    "    annot = pd.merge(resultsdf, annots_der)\n",
    "\n",
    "    return annot\n",
    "\n",
    "def get_comps(analysis):\n",
    "\n",
    "    comp1 = analysis.split(\"_\")[0] #\"der_v_bkgd\"\n",
    "    comp2 = analysis.split(\"_\")[2]\n",
    "    print(comp1, comp2)\n",
    "\n",
    "    return comp1, comp2\n",
    "\n",
    "def run_GO_enrichment(comp1, comp2, df, go, min_genes):\n",
    "    result_dict = {}\n",
    "    for process in go.Aspect.unique():\n",
    "        print(\"testing process\", process)\n",
    "        result_df = get_OR_go(comp1, comp2, df, process, MIN_GENES)\n",
    "\n",
    "        if result_df is not None:\n",
    "            annot_results = get_annot(result_df, go)\n",
    "            result_dict[process] = annot_results\n",
    "            results = pd.concat(result_dict.values())\n",
    "            results.sort_values(by = \"OR\")\n",
    "\n",
    "            return results\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    # concatenate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1d6861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T23:42:48.500198Z",
     "start_time": "2021-12-23T23:42:46.272366Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dors/capra_lab/projects/enhancer_ages/landscape/results/cCRE_x_tfbs_encode3/K562/data/K562_der_v_coreOR_per_MRCA.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e94e12f05b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgo_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_GO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mANALYSIS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6f00dcc91dc5>\u001b[0m in \u001b[0;36mget_df\u001b[0;34m(path, fdict_key)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdict_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdict_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# join the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dors/capra_lab/projects/enhancer_ages/landscape/results/cCRE_x_tfbs_encode3/K562/data/K562_der_v_coreOR_per_MRCA.tsv'"
     ]
    }
   ],
   "source": [
    "#%% set some constants\n",
    "\n",
    "F_DICT =  get_f_dict(CL)\n",
    "\n",
    "#%%\n",
    "## Load GO annotation file, TF enrichment in CL enhancers\n",
    "\n",
    "go_, go = load_GO()\n",
    "df = get_df(PATH, F_DICT[ANALYSIS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e09a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% test w/ min number of genes in group\n",
    "df.loc[df[\"reject_null\"] == True].groupby(\"mrca_2\")[\"tf\"].count()\n",
    "comp1, comp2 = get_comps(ANALYSIS)\n",
    "MIN_GENES = 10\n",
    "results = run_GO_enrichment(comp1, comp2, df, go, MIN_GENES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab46f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "results\n",
    "for n in results[\"name\"].unique():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284582d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# RUN AGE-SPECIFIC ANALYSIS W/ FOR LOOP HERE\n",
    "mrca_results = {}\n",
    "MIN_GENES = 5\n",
    "for mrca_2 in df.mrca_2.unique():\n",
    "    test = df.loc[df.mrca_2 == mrca_2]\n",
    "    results = run_GO_enrichment(comp1, comp2, test, go, MIN_GENES)\n",
    "    if results is not None:\n",
    "        results[\"mrca_2\"] = mrca_2\n",
    "        mrca_results[mrca_2] = results\n",
    "mrca_resultsdf = pd.concat(mrca_results.values())\n",
    "\n",
    "for n in mrca_resultsdf.name.unique():\n",
    "    print(n)\n",
    "#%%\n",
    "mrca_resultsdf\n",
    " syn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfenv)",
   "language": "python",
   "name": "sfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
