{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43524b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T01:11:19.175513Z",
     "start_time": "2022-05-18T01:11:18.145321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] bedfile\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fongsl/.conda/envs/sfenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Sarahfong\n",
    "\n",
    "\n",
    "# 2019-06-03 - created and run on common variants AF > 0.01\n",
    "\n",
    "##### updates #####\n",
    "\n",
    "# 2019-06-10\n",
    "    # AF calculation was not correct. 0.01<= AF <0.5 is the maf, and 0.5=<AF=<1 is the AF\n",
    "    # SNPs recalculated as maf.\n",
    "    # Instead of intersecting only common variants (AF >= 0.01), intersect all variants.\n",
    "    # maf rounded to 7th decimal\n",
    "\n",
    "\n",
    "# Analyze the genomic shuffle of FANTOM eRNA enhancers for breaks v. actual transcribed enhancers.\n",
    "\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "\n",
    "sys.path.append(\"/dors/capra_lab/users/fongsl/tools/py_/\")\n",
    "import config_readwrite as crw\n",
    "import plot_params as pp\n",
    "import split_filename\n",
    "\n",
    "pp.fonts()\n",
    "\n",
    "sys.path.append(\"/dors/capra_lab/users/fongsl/tools/genome/\")\n",
    "import make_windows \n",
    "import match_seq_lengths\n",
    "\n",
    "sys.path.append(\"/dors/capra_lab/users/fongsl/tools/evo/\")\n",
    "import syn_gen_background \n",
    "import linsight\n",
    "\n",
    "colors = [\"faded green\", \"greyish\",  \"amber\", \"dusty purple\", \"windows blue\",]\n",
    "palette = sns.xkcd_palette(colors)\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986559b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T01:13:17.440045Z",
     "start_time": "2022-05-18T01:13:17.424233Z"
    }
   },
   "outputs": [],
   "source": [
    "name = \"/dors/capra_lab/users/fongsl/enh_ages/core_v_derived/config_landscape\"\n",
    "config, config_filename = crw.read_config(name)\n",
    "\n",
    "RE = config[\"LINSIGHT\"][\"results\"]\n",
    "PY_SCRIPT = config[\"LINSIGHT\"][\"bin\"]\n",
    "\n",
    "\n",
    "BREAKS = config[\"FANTOM\"][\"data_file\"]  # original file on fantom enhancers and breaks. \n",
    "\n",
    "DERIVED = config[\"LINSIGHT\"][\"derived\"]\n",
    "CORE = config[\"LINSIGHT\"][\"core\"]\n",
    "SIMPLE = config[\"LINSIGHT\"][\"simple\"]\n",
    "SHUFFLE = config[\"LINSIGHT\"][\"shuffle\"]\n",
    "BUILD = \"hg19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e7ba7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-18T01:25:50.446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65503269, 17)\n"
     ]
    }
   ],
   "source": [
    "cols = [\"chr_syn\",\n",
    "        \"start_syn\", \"end_syn\", \n",
    "        \"enh_id\", \"chr_enh\",  \"start_enh\", \n",
    "        \"end_enh\", \"seg_index\", \"core_remodeling\", \"core\", \"mrca\", \"shuf_id\",\n",
    "       \"chr_lin\", \"start_lin\", \"end_lin\", \"linscore\", \"bin_overlap\"]\n",
    "shuf = pd.read_csv(SHUFFLE, sep = '\\t', \n",
    "                   header = None, \n",
    "                   names = cols, \n",
    "                   #nrows = 1000\n",
    "                  )\n",
    "\n",
    "print(shuf.shape)\n",
    "\n",
    "shuf.head()\n",
    "\n",
    "save_cols = [\"enh_id\", \"seg_index\", \"core_remodeling\", \"core\", \"mrca\", \"shuf_id\",\"linscore\", \"bin_overlap\"]\n",
    "\n",
    "out_der = \"/dors/capra_lab/projects/enhancer_ages/linsight/data/no-exon_shuffle_fantom_syn_breaks_clean_DERIVED_x_linsight.bed\"\n",
    "shuf.loc[shuf[\"core\"]==0, save_cols].to_csv(out_der, sep = '\\t', index = False)\n",
    "\n",
    "out_core = \"/dors/capra_lab/projects/enhancer_ages/linsight/data/no-exon_shuffle_fantom_syn_breaks_clean_CORE_x_linsight.bed\"\n",
    "shuf.loc[(shuf[\"core_remodeling\"]==1)&\n",
    "         (shuf[\"core\"]==1), save_cols].to_csv(out_core, sep = '\\t', index = False)\n",
    "out_simple = \"/dors/capra_lab/projects/enhancer_ages/linsight/data/no-exon_shuffle_fantom_syn_breaks_clean_SIMPLE_x_linsight.bed\"\n",
    "shuf.loc[(shuf[\"core_remodeling\"]==0)&\n",
    "         (shuf[\"core\"]==1), save_cols].to_csv(out_simple, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0a900",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-18T01:27:22.527Z"
    }
   },
   "outputs": [],
   "source": [
    "SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a62a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC = 0.5\n",
    "\n",
    "def load_syn_gen_bkgd(build):\n",
    "\n",
    "    F = f\"/dors/capra_lab/projects/enhancer_ages/{build}_syn_taxon.bed\"\n",
    "    syngenbkgd = pd.read_csv(F, sep='\\t')\n",
    "    syngenbkgd[[\"mrca\", \"mrca_2\"]] = syngenbkgd[[\"mrca\", \"mrca_2\"]].round(3)\n",
    "\n",
    "    return syngenbkgd\n",
    "\n",
    "\n",
    "def assign_architecture(df):\n",
    "\n",
    "    df[\"code\"] = \"\"\n",
    "    df.loc[(df.core_remodeling == 0)& (df.core == 1), \"code\"] = \"simple\"\n",
    "    df.loc[(df.core_remodeling == 1)& (df.core == 1), \"code\"] = \"complex_core\"\n",
    "    df.loc[(df.core_remodeling == 1)& (df.core == 0), \"code\"] = \"derived\"\n",
    "\n",
    "    df[\"arch\"] = \"\"\n",
    "    df.loc[(df.core_remodeling == 0), \"arch\"] = \"simple\"\n",
    "    df.loc[(df.core_remodeling == 1), \"arch\"] = \"complex\"\n",
    "\n",
    "    # create rank system for simple, core and derived segments\n",
    "    df[\"core_remodeling_2\"] = df.core_remodeling\n",
    "    df.loc[df[\"core\"] == 0, \"core_remodeling_2\"] = 2\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_fantom_encode_tfbs_overlap():\n",
    "    SYN_OVERLAP = '/dors/capra_lab/projects/enhancer_ages/landscape/results/fantom/encode3/ALL_FANTOM_SYN_TF_OVERLAP.tsv'\n",
    "    syn_tfbs_overlap = pd.read_csv(SYN_OVERLAP, sep = '\\t')\n",
    "\n",
    "    return syn_tfbs_overlap\n",
    "\n",
    "def load_untrimmed_fantom_ids():\n",
    "    map_trim = \"/dors/capra_lab/projects/enhancer_ages/fantom/data/trimmed-310_all_unique_fantom_erna_112_tissue.bed\"\n",
    "    trim_map = pd.read_csv(map_trim, sep = '\\t', header =None)\n",
    "    cols = [\"chr_en\"]\n",
    "\n",
    "\n",
    "def format_df(fantom_fs, syn_gen_bkgd):\n",
    "\n",
    "    arch_id = (fantom_fs.split(\"/\")[-1]).split(\"_\")[1]\n",
    "    print(arch_id)\n",
    "    df = pandas.read_csv(fantom_fs, sep = '\\t', header = None, low_memory=False)\n",
    "\n",
    "    # rename columns\n",
    "    df.columns = ['chr_syn','start_syn','end_syn', 'enh_id',\n",
    "                  'chr_enh', 'start_enh','end_enh',\n",
    "                  'seg_index', 'core_remodeling', 'core',\n",
    "                  'mrca', 'code', 'syn_id',\n",
    "                  \"chr_lin\",  \"start_lin\", \"end_lin\",\"linsight_score\", \"overlap\"]\n",
    "\n",
    "    # quantify lengths\n",
    "    df['enh_len'] = df.end_enh - df.start_enh\n",
    "    df['syn_len'] = df.end_syn - df.start_syn\n",
    "\n",
    "\n",
    "    core_age = df.groupby(\"enh_id\")['mrca'].max().reset_index()\n",
    "\n",
    "    # assign architecture, sub architectures\n",
    "    df = assign_architecture(df)\n",
    "\n",
    "    # Format LINSIGHT information\n",
    "    # exclude the loci that do not overlap a linsight score\n",
    "    df = df.loc[df.linsight_score != \".\"]\n",
    "\n",
    "    df.linsight_score = df.linsight_score.astype(float) # turn linsight scores into floats\n",
    "\n",
    "    df[\"linsight_id\"] = df.chr_lin + \":\" + df.start_lin.map(str) +\"-\"+ df.end_lin.map(str)\n",
    "\n",
    "    # make a dataframe only based on linsight scores and enhancer architectures\n",
    "\n",
    "    base_df = df[[\"chr_lin\", \"start_lin\", \"end_lin\", \"linsight_score\", \"code\", \"arch\", \"enh_id\", \"core_remodeling\", \"core_remodeling_2\"]].drop_duplicates()\n",
    "\n",
    "    base_df[\"lin_len\"] = base_df.end_lin - base_df.start_lin\n",
    "\n",
    "    # apply core age\n",
    "    base_df = pd.merge(base_df, core_age, how = \"left\", on = \"enh_id\")\n",
    "    base_df.mrca =base_df.mrca.round(3)\n",
    "    base_df = pd.merge(base_df, syn_gen_bkgd, how = \"left\", on = \"mrca\")\n",
    "\n",
    "    # remove id where architecture wasnt assigned\n",
    "    base_df = base_df.loc[base_df.code != \"\"]\n",
    "\n",
    "    # column for counting things.\n",
    "    base_df[\"counts\"] = 1\n",
    "    return base_df\n",
    "\n",
    "\n",
    "def plot_hist(derived, core, simple):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "    sns.distplot(derived, hist_kws=dict(cumulative=True),\n",
    "                     kde_kws=dict(cumulative=True), label = \"derived\", kde =False, norm_hist = True, color = \"blue\")\n",
    "    sns.distplot(core, hist_kws=dict(cumulative=True),\n",
    "                     kde_kws=dict(cumulative=True), label = \"complex core\", kde =False, norm_hist = True, color = \"purple\")\n",
    "    sns.distplot(simple, hist_kws=dict(cumulative=True),\n",
    "                     kde_kws=dict(cumulative=True), label = \"simple\", kde =False, norm_hist = True, color = \"gold\")\n",
    "\n",
    "    k, kp = stats.kruskal(simple, derived, core)\n",
    "\n",
    "    ax.set_title(\"FANTOM LINSIGHT scores\\nCumulative Distribution\")\n",
    "    ax.set_xlabel(\"LINSIGHT score\\nkruskal = %s, p = %s\" % (k, kp))\n",
    "    ax.set_ylabel(\"% of enhancer bases\")\n",
    "    ax.legend(bbox_to_anchor=(1.5, 1.0))\n",
    "\n",
    "    plt.savefig(\"%sfantom_linsight_architecture.pdf\" %(RE), bbox_inches = \"tight\")\n",
    "\n",
    "    return k, kp\n",
    "\n",
    "\n",
    "def get_expanded_arch_dfs(base_df):\n",
    "\n",
    "    # separate the dataframes by architevture and expand to bp level\n",
    "    simple_df = base_df.loc[base_df.code.str.contains(\"simple\")]\n",
    "    simple = np.repeat(simple_df.linsight_score, simple_df.lin_len) # expand linsight value for each simple basepair\n",
    "\n",
    "    derived_df = base_df.loc[base_df.code.str.contains(\"derived\")]\n",
    "    derived = np.repeat(derived_df.linsight_score, derived_df.lin_len)\n",
    "\n",
    "    core_df = base_df.loc[base_df.code.str.contains(\"core\")]\n",
    "    core = np.repeat(core_df.linsight_score, core_df.lin_len)\n",
    "\n",
    "    complexenh = pandas.concat([derived, core])\n",
    "\n",
    "    return simple, derived, core, complexenh\n",
    "\n",
    "\n",
    "def get_stats(concat):\n",
    "\n",
    "    medians = concat.groupby(\"code\")[\"linsight_score\"].median().reset_index()\n",
    "    medians[\"measurement\"] = \"median_linsight\"\n",
    "    means = concat.groupby(\"code\")[\"linsight_score\"].mean().reset_index()\n",
    "    means[\"measurement\"] = \"mean_linsight\"\n",
    "\n",
    "    measures = pd.concat([medians, means])\n",
    "    measures.to_csv(f\"{RE}fantom_linsight_score_summary.tsv\")\n",
    "\n",
    "    return measures\n",
    "\n",
    "\n",
    "def make_empty_dict(df, groupby_cols):\n",
    "    # for when i need an empty dictionary with a complete set of architectures and values\n",
    "    emptydf_dict = {}\n",
    "    val = 0 # unique identifier\n",
    "    if len(groupby_cols) == 2:\n",
    "        for mrca_2 in df[groupby_cols[0]].unique():\n",
    "            for arch in df[groupby_cols[1]].unique():\n",
    "\n",
    "                emptydf = pd.DataFrame({ groupby_cols[0]:[mrca_2], groupby_cols[1]:[arch],})\n",
    "                emptydf_dict[val] = emptydf\n",
    "                val+=1\n",
    "    elif len(groupby_cols) == 1:\n",
    "        for mrca_2 in df[groupby_cols[0]].unique():\n",
    "            emptydf = pd.DataFrame({ groupby_cols[0]:[mrca_2]})\n",
    "            emptydf_dict[val] = emptydf\n",
    "            val+=1\n",
    "    empty = pd.concat(emptydf_dict.values())\n",
    "    return empty\n",
    "\n",
    "\n",
    "def get_counts(df, groupby_cols, groupby_val):\n",
    "\n",
    "    counts = df.groupby(groupby_cols)[groupby_val].sum().reset_index()\n",
    "\n",
    "    if \"mrca_2\" in groupby_cols and \"core_remodeling\" in groupby_cols:\n",
    "\n",
    "        empty = make_empty_dict(df, groupby_cols) # make an empty df to fill architectures w/ no counts\n",
    "        counts = pd.merge(empty, counts, how = \"left\", on = groupby_cols).fillna(0)\n",
    "\n",
    "    elif \"mrca_2\" in groupby_cols and \"core_remodeling_2\" in groupby_cols:\n",
    "\n",
    "        empty = make_empty_dict(df, groupby_cols) # make an empty df to fill architectures w/ no counts\n",
    "        counts = pd.merge(empty, counts, how = \"left\").fillna(0)\n",
    "\n",
    "    # change count data to int\n",
    "    counts[groupby_val] = counts[groupby_val].astype(int)\n",
    "\n",
    "    # sort and reset the index. Seaborn plots by index value.\n",
    "    counts = counts.sort_values(by = groupby_cols).reset_index()\n",
    "\n",
    "    # drop the index column.\n",
    "    counts = counts.drop([\"index\"], axis = 1)\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "def plot_annotate_counts(splot, counts_df, groupby_val, height_adjust):\n",
    "\n",
    "    # annotate plot with counts\n",
    "    for n, p in enumerate(splot.patches):\n",
    "\n",
    "        value = counts_df.iloc[n][groupby_val].astype(int)\n",
    "        #print(n, p, value)\n",
    "        if height_adjust == 0:\n",
    "            height_adjust = (p.get_height()-0.03)\n",
    "\n",
    "\n",
    "        splot.annotate(value,\n",
    "                       (p.get_x() + p.get_width() / 2.,height_adjust),\n",
    "                       ha = 'center', va = 'baseline',\n",
    "                       size=15,\n",
    "                       rotation = 90,\n",
    "                       color = \"k\",\n",
    "                       xytext = (0, 1),\n",
    "                       textcoords = 'offset points'\n",
    "                       )\n",
    "\n",
    "\n",
    "def plot_figure3(df, fig_id, re, trim_len, frac, dataset, x):\n",
    "\n",
    "    # for ranking and stratifying by age and architecture, set x1 for counts\n",
    "    if x == 'arch':\n",
    "        x1 = \"core_remodeling\"\n",
    "        pal = palette\n",
    "        order_labs = [\"simple\", \"complex\"]\n",
    "        order = [0,1]\n",
    "    elif x == \"code\":\n",
    "        x1 = \"core_remodeling_2\"\n",
    "        pal = arch_palette\n",
    "        order_labs = [\"simple\", \"core\", \"derived\"]\n",
    "        order = [0,1,2]\n",
    "\n",
    "    xlab = ['Homo', 'Prim', 'Euar', 'Bore', 'Euth', 'Ther', 'Mam',\n",
    "    'Amni', 'Tetr', 'Vert']\n",
    "\n",
    "    title = dataset\n",
    "\n",
    "    # set up plot\n",
    "    sns.set(\"poster\")\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 3])\n",
    "    ax = plt.subplot(gs[0])\n",
    "\n",
    "    # plot the first panel\n",
    "    y = \"linsight_score\"\n",
    "    data = df\n",
    "\n",
    "    splot = sns.barplot(x = x1, y = y, data = data,\n",
    "                palette = pal, order = order,\n",
    "                ax = ax)\n",
    "\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.set_xticklabels(order_labs, rotation = 90)\n",
    "\n",
    "    # get counts for annotation\n",
    "    groupby_cols, groupby_val = [x1], \"lin_len\"\n",
    "    countdf = get_counts(df, groupby_cols, groupby_val)\n",
    "    height_adjust = 0.01\n",
    "    plot_annotate_counts(splot, countdf, groupby_val, height_adjust)\n",
    "\n",
    "    # plot the second panel\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "\n",
    "    x, y = \"mrca_2\", \"linsight_score\"\n",
    "    data = df.sort_values(by = \"mrca_2\")\n",
    "    hue = x1\n",
    "\n",
    "    # plot mrca-stratified barplot\n",
    "\n",
    "    mplot = sns.barplot(x = x, y = y, data = data,\n",
    "                hue = hue,\n",
    "                palette = pal,\n",
    "                ax = ax2)\n",
    "\n",
    "    # add counts and annotate barplot\n",
    "    groupby_cols, groupby_val = [x1, \"mrca_2\"], \"lin_len\"\n",
    "    countdf = get_counts(df, groupby_cols, groupby_val)\n",
    "    plot_annotate_counts(mplot, countdf, groupby_val, height_adjust)\n",
    "\n",
    "    # plot x labels\n",
    "    ax2.set_xticklabels(xlab, rotation = 90)\n",
    "    ax2.set(xlabel = \"\", ylabel = \"\", title = title)\n",
    "\n",
    "    ax2.legend().remove()\n",
    "\n",
    "    ax2.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "    ax2lim = ax2.get_ylim()\n",
    "    # set first plot lim based on second plot lim\n",
    "    ax.set(xlabel = \"\", ylabel = \"linsight score\", ylim = ax2lim)\n",
    "\n",
    "    outf = f\"{re}fig{fig_id}_LINSIGHT_{trim_len}_noexon_{dataset}_{frac}_mrcas.pdf\"\n",
    "\n",
    "    plt.savefig(outf, bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "#%% expand linsight score estimates across bases\n",
    "\n",
    "syn_gen_bkgd = load_syn_gen_bkgd(BUILD)\n",
    "\n",
    "syn_tfbs_overlap = load_fantom_encode_tfbs_overlap() # merge infor about ENCODE3 TFBS overlap\n",
    "\n",
    "base_df = format_df(fantom_fs, syn_gen_bkgd)\n",
    "\n",
    "base_df.head()\n",
    "\n",
    "base_df = pd.merge(base_df, syn_tfbs_overlap, how = \"left\")\n",
    "#%%\n",
    "\n",
    "# expand linsight counts to per basepair level\n",
    "simple, derived, core, complexnh = get_expanded_arch_dfs(base_df)\n",
    "\n",
    "k, kp = plot_hist(derived, core, simple)\n",
    "\n",
    "#%%\n",
    "\n",
    "simplef = simple.to_frame()\n",
    "simplef[\"code\"] = \"simple\"\n",
    "simplef[\"arch\"] = \"simple\"\n",
    "\n",
    "derivedf = derived.to_frame()\n",
    "derivedf[\"code\"] = \"derived\"\n",
    "derivedf[\"arch\"] = \"complex\"\n",
    "\n",
    "coref = core.to_frame()\n",
    "coref[\"code\"] = \"complex_core\"\n",
    "coref[\"arch\"] = \"complex\"\n",
    "\n",
    "concat = pandas.concat([simplef, derivedf, coref])\n",
    "concat = concat.sample(frac = 0.05)\n",
    "\n",
    "\n",
    "#%%\n",
    "measures = get_stats(concat)\n",
    "\n",
    "\n",
    "#%%\n",
    "FIG_ID = \"3C\"\n",
    "DATASET = \"all_fantom_enh\"\n",
    "x = \"arch\"\n",
    "\n",
    "plot_figure3(base_df, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "#%% plot only enhancers that overlap TFBS in ENCODE\n",
    "\n",
    "FIG_ID = \"3C\"\n",
    "DATASET = \"TFBS_overlap_only_all_fantom_enh\"\n",
    "x = \"arch\"\n",
    "data = base_df.loc[base_df.tfoverlap_bin ==1]\n",
    "data.shape\n",
    "plot_figure3(data, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "FIG_ID = \"3C\"\n",
    "DATASET = \"NO_TFBS_all_fantom_enh\"\n",
    "x = \"arch\"\n",
    "no_data = base_df.loc[base_df.tfoverlap_bin ==0]\n",
    "\n",
    "plot_figure3(no_data, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "FIG_ID = \"3A\"\n",
    "DATASET = \"all_fantom_enh\"\n",
    "x = \"code\"\n",
    "plot_figure3(base_df, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "#%% evaluate linsight on syntenic architecture w/ evidence for TFBS binding in encode\n",
    "\n",
    "\n",
    "FIG_ID = \"3A\"\n",
    "DATASET = \"TFBS_overlap_only_all_fantom_enh\"\n",
    "x = \"code\"\n",
    "data = base_df.loc[base_df.tfoverlap_bin ==1]\n",
    "plot_figure3(data, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "\n",
    "#%% evaluate linsight on syntenic architecture w/ no evidence for TFBS binding\n",
    "\n",
    "\n",
    "FIG_ID = \"3A\"\n",
    "DATASET = \"NO_TFBS_all_fantom_enh\"\n",
    "x = \"code\"\n",
    "nodata = base_df.loc[base_df.tfoverlap_bin ==0]\n",
    "plot_figure3(nodata, FIG_ID, RE, TRIM_LEN, FRAC, DATASET, x)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "order = [\"simple\", \"complex\"]\n",
    "fig, ax = plt.subplots(figsize= (8,8))\n",
    "sns.boxplot( x = \"arch\", y = \"linsight_score\", data = sample2.loc[sample2.mrca_2> 0.175],\n",
    "            notch = True, order = order, palette = pal)\n",
    "old = sample2.loc[sample2.mrca_2> 0.175]\n",
    "m, mp = stats.mannwhitneyu(old.loc[old.arch.str.contains(\"complex\"), \"linsight_score\"],\n",
    "                          old.loc[old.arch.str.contains(\"simple\"), \"linsight_score\"])\n",
    "print(m,mp)\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "\n",
    "old.groupby(\"arch\")[\"linsight_score\"].mean()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "sample2.head()\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "kw_list = []\n",
    "for i in sample2.mrca_2.unique():\n",
    "    mrca_list = sample2.loc[sample2.mrca_2 == i, \"linsight_score\"].to_list()\n",
    "    kw_list.append(mrca_list)\n",
    "from scipy.stats import mstats\n",
    "\n",
    "args=[l for l in kw_list]\n",
    "stats.mstats.kruskalwallis(*args)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "core_age = df.groupby([\"enh_id\"])[\"mrca\"].max().reset_index()\n",
    "core_age = pandas.merge(core_age, syn_gen_bkgd) # add in taxon2\n",
    "core_age = core_age[[\"enh_id\", \"mrca_2\"]]\n",
    "core_age.columns = [\"enh_id\", \"mrca_2_core\"]\n",
    "core_age.sort_values(by=\"mrca_2_core\").head()\n",
    "\n",
    "\n",
    "# # Two-way ANOVA does not work because\n",
    "# Independent observations - yes\n",
    "# Residue distribution is normal - no (Jarque-bera)\n",
    "# homogeneity of variance - no (Omnibus)\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "sample2.head()\n",
    "\n",
    "\n",
    "# In[108]:\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "sample3 = base_df.sample(frac =0.01)\n",
    "# Fits the model with the interaction term\n",
    "# This will also automatically include the main effects for each factor\n",
    "model = ols('linsight_score ~ C(mrca_2)*C(arch)', sample3).fit()\n",
    "\n",
    "# Seeing if the overall model is significant\n",
    "print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "subset = sample3[['mrca', 'arch',]].drop_duplicates()\n",
    "tuples = [tuple(x) for x in subset.to_numpy()]\n",
    "tuples\n",
    "\n",
    "resid = model.resid\n",
    "factor_groups = sample3.groupby(['mrca_2','arch'])\n",
    "\n",
    "plt.figure(figsize=(6,6));\n",
    "for values, group in factor_groups:\n",
    "    i,j = values\n",
    "    group_num = i*100  # for plotting purposes\n",
    "    x = [group_num] * len(group)\n",
    "    plt.scatter(x, resid[group.index],\n",
    "            s=10)\n",
    "plt.xlabel('Group');\n",
    "plt.ylabel('Residuals');\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "res = sm.stats.anova_lm(model, typ= 2)\n",
    "res\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfenv)",
   "language": "python",
   "name": "sfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
