{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys, traceback\n",
    "import argparse\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import glob\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from pybedtools import BedTool\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_break(df, id_dict, iteration):\n",
    "\n",
    "    i = id_dict[iteration] # get the enh_id\n",
    "    \n",
    "    test = df[[\"chr_enh\",  # filter df to only enh_id\n",
    "                   \"start_enh\", \"end_enh\",\"chr_syn\",\"start_syn\",\"end_syn\",\n",
    "                   \"mrca\",\"len_syn_overlap\",\"test_id\"]]\\\n",
    "        .loc[df[\"test_id\"]==i]\\\n",
    "        .drop_duplicates()\\\n",
    "        .sort_values([\"chr_syn\",\"start_syn\",\"end_syn\"]).reset_index()\n",
    "    \n",
    "    new_data = test[[\"chr_enh\",\"start_enh\", \"end_enh\",\"test_id\", \"chr_syn\"]]\\\n",
    "    .drop_duplicates()# new dataframe for reassembled breaks\n",
    "\n",
    "    collect_df = pd.DataFrame()\n",
    "\n",
    "    age_seg = [(round(age,3), sum(1 for i in rows)) for age,rows in groupby(test[\"mrca\"])]\n",
    "\n",
    "    start, end = test[\"start_enh\"].astype(int), test[\"end_enh\"].astype(int)\n",
    "\n",
    "    df_index = 0\n",
    "    seg_index = 0\n",
    "    core_age = max(i for i, k in age_seg) # GET OLDEST/MAX AGE\n",
    "    \n",
    "    for tup in age_seg:\n",
    "        age, idx = tup\n",
    "\n",
    "        if len(age_seg)== 1: # SIMPLE\n",
    "\n",
    "            new_data[\"start_syn\"] = start\n",
    "            new_data[\"end_syn\"] = end\n",
    "            new_data[\"mrca_seg\"] = age\n",
    "            new_data[\"seg_index\"] = 0 # index syntenic segments\n",
    "            new_data[\"core\"] = 1 # binary core measure\n",
    "            new_data[\"core_remodeling\"] = 0 # binary core remodeling measure\n",
    "            collect_df= collect_df.append(new_data)\n",
    "\n",
    "        else: # COMPLEX\n",
    "\n",
    "            new_data[\"seg_index\"]= seg_index # index syntenic segments\n",
    "            new_data[\"core_remodeling\"] = 1 # binary core remodeling measure\n",
    "\n",
    "            if age == core_age: # OLDEST AGE\n",
    "                new_data[\"core\"] = 1\n",
    "\n",
    "            else:\n",
    "                new_data[\"core\"] = 0\n",
    "\n",
    "            if seg_index == 0: # trim first syntenic block to start\n",
    "                new_data[\"start_syn\"] = start\n",
    "                new_data[\"end_syn\"] = test.loc[idx-1, \"end_syn\"]\n",
    "\n",
    "                new_data[\"mrca_seg\"] = round(age, 3)\n",
    "                collect_df= collect_df.append(new_data)\n",
    "\n",
    "            elif seg_index == len(age_seg)-1: # trim last syntenic block\n",
    "                new_data[\"mrca_seg\"] = age\n",
    "                new_data[\"start_syn\"] = test.loc[df_index, \"start_syn\"]\n",
    "                new_data[\"end_syn\"] = end\n",
    "                collect_df= collect_df.append(new_data)\n",
    "\n",
    "            else: # deal with all the blocks in between first and last syntenic block\n",
    "                new_data[\"mrca_seg\"] = age\n",
    "                new_data[\"start_syn\"]= test.loc[df_index, \"start_syn\"]\n",
    "                new_data[\"end_syn\"]= test.loc[df_index + idx -1, \"end_syn\"]\n",
    "                collect_df= collect_df.append(new_data)\n",
    "\n",
    "        df_index +=idx # go to next index\n",
    "        seg_index +=1 # count age segments\n",
    "\n",
    "    return collect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_tfbs(concat_file, sample_id, test_path):\n",
    "\n",
    "    inpath = \"%s/ages/\" % test_path # mkdir ./ages/\n",
    "    outpath = \"%s/breaks/\" % test_path # mkdir ./break/\n",
    "    #mkdir(outpath) \n",
    "\n",
    "    age_breaks_out = \"%s%s_age_breaks.bed\" % (outpath, sample_id)\n",
    "    touch = \"touch %s\" %age_breaks_out\n",
    "    print(touch)\n",
    "    os.system(touch)\n",
    "    \n",
    "    df = pd.read_csv(concat_file, sep = '\\t', header = None , low_memory=False) # open up the bed file and assemble breaks.\n",
    "\n",
    "    df.columns = [\"chr_enh\", \"start_enh\", \"end_enh\",\"chr_syn\",\n",
    "                  \"start_syn\",\"end_syn\",\"strand\",\"ref\",\"num_species\",\n",
    "                  \"len_syn\",\"mrca\",\"patr\",\"len_syn_overlap\"]# rename the columns\n",
    "\n",
    "    df[\"test_id\"] = df[\"chr_enh\"] + \":\" + df[\"start_enh\"].map(str) + \"-\" + df[\"end_enh\"].map(str) # add a test_id\n",
    "\n",
    "    df = df.loc[df[\"len_syn_overlap\"]>0] # remove all the records that do not overlap syntenic blocks\n",
    "\n",
    "    ENH_COUNT = len(df[\"test_id\"].unique())\n",
    "    print(\"unique enhancers =\", ENH_COUNT) # count the number of enhancers\n",
    "\n",
    "    print(\"# rows to reduce and assemble breaks = \", len(df.drop_duplicates())) # drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #####\n",
    "    # prepare to join breaks\n",
    "    #####\n",
    "\n",
    "    df[\"mrca\"] = df[\"mrca\"].astype(float).round(3) # round MRCA distance\n",
    "\n",
    "    id_list = df[\"test_id\"].unique() # get enh_ids\n",
    "    id_dict = dict(enumerate(df[\"test_id\"].unique())) # dictionary of enhancer ids\n",
    "    #####\n",
    "    # start the break assembly\n",
    "    #####\n",
    "    start = datetime.now()\n",
    "    print(\"Start assembling breaks\", start)\n",
    "\n",
    "\n",
    "    val = 0\n",
    "    end_val = len(id_list)\n",
    "    num_threads = 500\n",
    "\n",
    "    while val <  end_val:\n",
    "\n",
    "        print(val, end_val)\n",
    "\n",
    "        if end_val - val > num_threads:\n",
    "            new_range = np.arange(num_threads) + val\n",
    "        else: \n",
    "            num_threads = abs(end_val - val)\n",
    "\n",
    "            new_range = np.arange(num_threads) + val\n",
    "            print(end_val,\"minus\", val, \"equals\", num_threads)\n",
    "\n",
    "        pool = Pool(num_threads)\n",
    "        partial_calcExp = partial(assemble_break, df, id_dict)\n",
    "        results = pool.map(partial_calcExp, [i for i in new_range])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "\n",
    "        temp = pd.concat(results)\n",
    "        temp = temp[['chr_syn','start_syn','end_syn','test_id',\n",
    "                         'chr_enh','start_enh','end_enh','seg_index',\n",
    "                         'core_remodeling','core','mrca_seg']]\n",
    "        with open(age_breaks_out, 'a') as f:\n",
    "                temp.to_csv(f, sep = '\\t', header = False, index = False) # write last enhancers   \n",
    "        val +=num_threads\n",
    "\n",
    "    clean_up = \"rm %s\" % concat_file # cleanup the input file\n",
    "    os.system(clean_up)\n",
    "\n",
    "    print(\"Finished assembling breaks\", datetime.now())\n",
    "\n",
    "    return age_breaks_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "touch /dors/capra_lab/projects/enhancer_ages/fantom/data/shuffle/breaks/test_age_breaks.bed\n",
      "unique enhancers = 19\n",
      "# rows to reduce and assemble breaks =  100\n",
      "Start assembling breaks 2020-02-11 11:55:50.375243\n",
      "0 19\n",
      "19 minus 0 equals 19\n",
      "Finished assembling breaks 2020-02-11 11:55:51.384096\n"
     ]
    }
   ],
   "source": [
    "path = \"/dors/capra_lab/projects/enhancer_ages/fantom/data/shuffle\"\n",
    "file = \"%s/test.bed\" % path\n",
    "\n",
    "df = break_tfbs(file, \"test\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dors/capra_lab/projects/enhancer_ages/fantom/data/shuffle/breaks/test_age_breaks.bed'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfenv)",
   "language": "python",
   "name": "sfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
