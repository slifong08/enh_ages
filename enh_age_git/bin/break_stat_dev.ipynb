{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CUTOFF] [-s SAMPLE01] age_break\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys, traceback\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats\n",
    "\n",
    "# TO RUN\n",
    "\n",
    "# python script input_file sample_id\n",
    "\n",
    "# python /dors/capra_lab/fongsl/enh_age/bin/age_enhancers.py UBERON_0002372_tonsil_expressed_enhancers.bed UBERON0002372\n",
    "\n",
    "\n",
    "###\n",
    "#   arguments\n",
    "###\n",
    "arg_parser = argparse.ArgumentParser(description=\"Calculate enhancer age.\")\n",
    "\n",
    "arg_parser.add_argument(\"age_break\", help='break file 1 (enhancers to age) w/ full path')\n",
    "\n",
    "arg_parser.add_argument(\"-c\", \"--cutoff\", type=int, default=10000,\n",
    "                        help='threshold enhancer lengths; default=10000')\n",
    "\n",
    "arg_parser.add_argument(\"-s\", \"--sample01\", type=int, default=0,\n",
    "                        help='sample 10% of dataset')\n",
    "\n",
    "args = arg_parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# CONSTANTS\n",
    "###\n",
    "\n",
    "#F = args.age_break\n",
    "F = \"/dors/capra_lab/projects/enhancer_ages/roadmap_encode/data/hg19_roadmap_samples_enh_age/tfbs/ucsc_tfbs/E098_x_ucsc_tfbs_midpeak.bed\"\n",
    "#SOURCE_F = args.age_break\n",
    "SOURCE_F = F\n",
    "\n",
    "#LEN_CUTOFF = args.cutoff\n",
    "LEN_CUTOFF = 10000\n",
    "#SAMPLE_TEN_PERCENT = args.sample01\n",
    "SAMPLE_TEN_PERCENT= 0\n",
    "PATH = \"/\".join(F.split(\"/\")[:-1])\n",
    "SAMPLE_ID = (F.split(\"/\")[-1]).split(\".\")[0]\n",
    "#F = \"%s/breaks/%s_age_breaks.bed\" % (PATH, SAMPLE_ID) \n",
    "OUTPATH = \"%s/stats/\" % PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dors/capra_lab/users/fongsl/sfenv/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/dors/capra_lab/users/fongsl/sfenv/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (524509, 21) after dropping duplicates (197950, 21)\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "# functions\n",
    "###\n",
    "\n",
    "def mkdir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        cmd = \"mkdir %s\" % path\n",
    "        os.system(cmd)\n",
    "mkdir(OUTPATH)\n",
    "        \n",
    "\n",
    "def format_df(df, sample_id, sample_ten_percent, len_cutoff, syn_gen_bkgd, outpath):\n",
    "    df = df[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    "    \n",
    "    df.columns = [\"chr_syn\", 'start_syn','end_syn',\"enh_id\", 'chr_enh','start_enh',\n",
    "                      'end_enh','seg_index','core_remodeling','core','mrca'] # name 11 columns\n",
    "    \n",
    "    df[\"sid\"]= sample_id # label sample id\n",
    "    \n",
    "    df[\"enh_len\"] = (df[\"end_enh\"] - df[\"start_enh\"]) # enh length calculation\n",
    "\n",
    "    \n",
    "    df = df.loc[df.chr_syn !=\"chrX\"] # autosomes only\n",
    "    \n",
    "    # remove complex enhancers from 0.00 mrca. This is no bueno. \n",
    "    s = df.groupby([\"enh_id\", \"core_remodeling\"])[\"mrca\"].max().reset_index()\n",
    "    s = s.enh_id.loc[(s.mrca==0.000)&(s.core_remodeling==1)].tolist()\n",
    "\n",
    "    df = df[~df.enh_id.isin(s)] # exlude all the data that is mislabeled. \n",
    "    if sample_ten_percent == 1:\n",
    "            \n",
    "        if len_cutoff > 0:\n",
    "            enh_ids = df.loc[df[\"enh_len\"]<= len_cutoff, \"enh_id\"].unique() # get a unique list of enhancer ids\n",
    "        else:\n",
    "            enh_ids = df[\"enh_id\"].unique() # get a unique list of enhancer ids\n",
    "\n",
    "        tenpercent = int(round(len(enh_ids)/10, 0)) # int for 10% of ids\n",
    "            \n",
    "        print(\"0.1 of %s enhancers\" % sample_id, len(enh_ids), \"is\", tenpercent)\n",
    "\n",
    "        sampled = np.random.choice(enh_ids,tenpercent) # select 10% of ids at random\n",
    "\n",
    "        sampled_df = pd.DataFrame({\"enh_id\": sampled}) # make a new dataframe\n",
    "\n",
    "        # get syntenic block information for 10% shuffled enhancer ids\n",
    "\n",
    "        df = pd.merge(sampled_df, df,  how = \"left\", on = \"enh_id\") # write over shuffle_df.\n",
    "\n",
    "    else:\n",
    "        if len_cutoff > 0:\n",
    "            df = df.loc[df.enh_len<= len_cutoff]\n",
    "    \n",
    "    ###\n",
    "    # break pseudocount\n",
    "    # enh len\n",
    "    # syn len\n",
    "    # percent of enhancer\n",
    "    # syn id\n",
    "    # enh id\n",
    "    #\n",
    "    # code\n",
    "    #\n",
    "    # filter synetnic blocks <9bp long\n",
    "    # merge taxon, mrca_2\n",
    "    ###\n",
    "    df[\"seg_index\"] = df[\"seg_index\"] +1 # pseudocount for break density\n",
    "\n",
    "    df[\"syn_len\"] = (df[\"end_syn\"] - df[\"start_syn\"]) # syntenic length calculation\n",
    "    df[\"seg_rep\"] = df[\"syn_len\"]/df[\"enh_len\"] # percent of the enhancer occupied by each syntenic block\n",
    "    df[\"syn_id\"] = df[\"chr_syn\"]+ \":\" + df[\"start_syn\"].map(str) + \"-\" + df[\"end_syn\"].map(str)\n",
    "    df[\"enh_id\"] = df[\"chr_enh\"]+ \":\" + df[\"start_enh\"].map(str) + \"-\" + df[\"end_enh\"].map(str)\n",
    "\n",
    "    df[\"code\"] = \"\"\n",
    "    df.loc[df[\"core\"] == 0 & (df[\"core_remodeling\"] == 1), \"code\"] = \"derived\"\n",
    "    df.loc[(df[\"core\"] == 1) & (df[\"core_remodeling\"] == 1), \"code\"] = \"complex_core\"\n",
    "    df.loc[(df[\"core\"] == 1) & (df[\"core_remodeling\"] == 0),  \"code\"] = \"simple\"\n",
    "    \n",
    "    df[\"arch\"] = \"\"\n",
    "    df.loc[(df[\"core_remodeling\"] == 1),\"arch\"] = \"complexenh\"\n",
    "    df.loc[(df[\"core_remodeling\"] == 0), \"arch\"] = \"simple\"\n",
    "\n",
    "    ###FILTER###\n",
    "\n",
    "    df = df.loc[df[\"syn_len\"]>=6]\n",
    "\n",
    "    df[\"mrca\"]=df[\"mrca\"].round(3)\n",
    "\n",
    "    df = pd.merge(df, syn_gen_bkgd, how = \"left\", on = \"mrca\")\n",
    "\n",
    "    before_shape = df.shape\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"before\", before_shape, \"after dropping duplicates\", df.shape) \n",
    "\n",
    "   \n",
    "    return df\n",
    "\n",
    "def get_data_stats(df, sid, dataset, outpath, syn_gen_bkgd):\n",
    "    \n",
    "    write_dict = {}\n",
    "    \n",
    "    ### SHUF len per age ###\n",
    "    df[\"mrca\"] = df[\"mrca\"].round(3)\n",
    "    df[\"mrca_2\"] = df[\"mrca_2\"].round(3)\n",
    "\n",
    "    df_all = df.groupby(\"core_remodeling\").describe().reset_index() # groupby simple and complex and get basic stats\n",
    "\n",
    "    all_dict = {}\n",
    "    all_val = 0\n",
    "    for cr, new_df in df_all.groupby(level=0): # break apart the levels of the groupby and collect stats\n",
    "        a = pd.melt(new_df)\n",
    "        a.columns = [\"var\", \"varStat\", \"varVal\"]\n",
    "        a[\"core_remodeling\"] = cr\n",
    "\n",
    "        a[\"sid\"] = sid\n",
    "        a[\"dataset\"] = dataset\n",
    "        key = str(cr)+ \"-\"+ str(all_val)\n",
    "        all_val +=1\n",
    "        all_dict[key] = a\n",
    "        \n",
    "    df_all_ = pd.concat(all_dict.values())\n",
    "        \n",
    "    write_dict[\"BASIC\"] = df_all_\n",
    "    df_all_.to_csv(\"%s%s-df_basic_arch_stats.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "    \n",
    "    new_lens = df.groupby([\"enh_id\", \"core_remodeling\", \"enh_len\"])[\"mrca_2\"].max().reset_index()\n",
    "    new_lens.columns = [\"id\", \"core_remodeling\", \"len\", \"mrca_2\"]\n",
    "\n",
    "    lens = pd.merge(new_lens, syn_gen_bkgd)\n",
    "\n",
    "    ### ENHANCERS LEN DESC ALL \n",
    "\n",
    "    desc_all = lens.groupby(\"mrca_2\")[\"len\"].describe().reset_index()\n",
    "    desc_all = pd.melt(desc_all, id_vars=['mrca_2'], value_vars=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "    desc_all.columns = [\"mrca_2\", \"len_cat\", \"len_stat\"]\n",
    "    desc_all[\"dataset\"] = dataset\n",
    "    desc_all[\"sid\"] = sid\n",
    "    write_dict[\"enh_len_stats\"] = desc_all\n",
    "    desc_all.to_csv(\"%s%s-enh_len_stats.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "\n",
    "    ### ENHANCERS LEN DESC W/ ENHANCER ARCH, AGE\n",
    "    desc_arch = lens.groupby([\"mrca_2\", \"core_remodeling\"])[\"len\"].describe().reset_index()\n",
    "    desc_arch = pd.melt(desc_arch, id_vars=[\"mrca_2\", \"core_remodeling\"], value_vars=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "    desc_arch.columns = [\"mrca_2\",\"core_remodeling\", \"len_cat\", \"len_stat\", ]\n",
    "    desc_arch[\"dataset\"] = dataset\n",
    "    desc_arch[\"sid\"] = sid\n",
    "    write_dict[\"enh_arch_len_stats\"] = desc_arch\n",
    "    desc_arch.to_csv(\"%s%s-enh_arch_len_stats.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "    \n",
    "    ### SYN LEN DESC w/ ARCH, AGE\n",
    "    syn_lens = df.groupby([\"syn_id\", \"code\", \"syn_len\"])[\"mrca_2\"].max().reset_index()\n",
    "\n",
    "    syn_lens.columns = [\"id\", \"code\", \"len\", \"mrca_2\"]\n",
    "    \n",
    "    syn_lens_desc = syn_lens.groupby([\"mrca_2\", \"code\"])[\"len\"].describe().reset_index()\n",
    "    syn_lens_desc = pd.melt(syn_lens_desc, id_vars=[\"mrca_2\", \"code\"], value_vars=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "    syn_lens_desc.columns = [\"mrca_2\",  \"code\",\"len_cat\", \"len_stat\"]\n",
    "    syn_lens_desc[\"dataset\"] = dataset\n",
    "    syn_lens_desc[\"sid\"] = sid\n",
    "    write_dict[\"syn_len_stats\"] = syn_lens_desc\n",
    "\n",
    "    syn_lens_desc.to_csv(\"%s%s-syn_len_stats.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "\n",
    "    ### REGRESSION MRCA x LEN - calculate slope of the line\n",
    "    xs = lens.mrca_2.loc[lens.core_remodeling ==0]\n",
    "    ys = lens.len.loc[lens.core_remodeling ==0]\n",
    "\n",
    "    slope_ss, intercept_ss, r_value_ss, p_value_ss, std_err_ss = stats.linregress(xs,ys)\n",
    "\n",
    "    xc = lens.mrca_2.loc[lens.core_remodeling ==1]\n",
    "    yc = lens.len.loc[lens.core_remodeling ==1]\n",
    "\n",
    "    slope_cs, intercept_cs, r_value_cs, p_value_cs, std_err_cs = stats.linregress(xc,yc)\n",
    "    \n",
    "    xcore = syn_lens.mrca_2.loc[syn_lens.code.str.contains(\"core\")]\n",
    "    ycore = syn_lens.len.loc[syn_lens.code.str.contains(\"core\")]\n",
    "\n",
    "    slope_core, intercept_core, r_value_core, p_value_core, std_err_core = stats.linregress(xcore,ycore)\n",
    "    \n",
    "    xd = syn_lens.mrca_2.loc[syn_lens.code.str.contains(\"derived\")]\n",
    "    yd = syn_lens.len.loc[syn_lens.code.str.contains(\"derived\")]\n",
    "\n",
    "    slope_d, intercept_d, r_value_d, p_value_d, std_err_d = stats.linregress(xd,yd)\n",
    "\n",
    "    lin_regression = pd.DataFrame({\"m\": [slope_ss, slope_cs, slope_core, slope_d],\n",
    "                                       \"b\": [intercept_ss, intercept_cs, intercept_core, intercept_d],\n",
    "                                       \"r\": [r_value_ss,r_value_cs, r_value_core, r_value_d],\n",
    "                                       \"p\": [p_value_ss, p_value_cs, p_value_core, p_value_d],\n",
    "                                      \"arch\":[\"simple\", \"complexenh\", \"complexcore\", \"derived\"],\n",
    "                                      \"sid\": [sid, sid, sid, sid], \n",
    "                                      \"dataset\" : [dataset, dataset, dataset, dataset]})\n",
    "    \n",
    "    write_dict[\"linear_regression\"] = lin_regression\n",
    "    lin_regression.to_csv(\"%s%s-linear_regression.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "\n",
    "    ###  break frequency ###\n",
    "    breaks = df.groupby([\"enh_id\"])[\"seg_index\"].max().reset_index()\n",
    "    breaks_freq = breaks.groupby(\"seg_index\")[\"enh_id\"].count().reset_index()\n",
    "    totals = len(breaks)\n",
    "    breaks_freq[\"freq\"] = breaks_freq[\"enh_id\"].divide(totals)\n",
    "    breaks_freq[\"sid\"] = sid\n",
    "    breaks_freq[\"dataset\"] = dataset\n",
    "\n",
    "    write_dict[\"break_freq\"] = breaks_freq\n",
    "    breaks_freq.to_csv(\"%s%s-break_freq.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "    \n",
    "    ###  break age ###\n",
    "    breaks_mrca = df.groupby([\"enh_id\"])[\"seg_index\", \"mrca_2\"].max().reset_index()\n",
    "    breaks_mrca = breaks_mrca.groupby([\"mrca_2\"])[\"seg_index\"].describe().reset_index()\n",
    "    breaks_mrca = pd.melt(breaks_mrca, id_vars=[\"mrca_2\",], value_vars=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "    breaks_mrca.columns = [\"mrca_2\", \"break_cat\", \"break_stat\", ]\n",
    "    breaks_mrca[\"sid\"] = sid\n",
    "    breaks_mrca[\"dataset\"] = dataset\n",
    "    \n",
    "    write_dict[\"breaks_mrca\"] = breaks_mrca\n",
    "    breaks_mrca.to_csv(\"%s%s-breaks_mrca.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "    \n",
    "    ### enh age, arch dataset frequencies ###\n",
    "    enh_age_freq = lens.groupby([\"mrca_2\", \"core_remodeling\"])[\"id\"].count().reset_index()\n",
    "\n",
    "    enh_age_freq.columns = [\"mrca_2\", \"core_remodeling\", \"count_ids\"]\n",
    "    \n",
    "    enh_age_freq[\"totals\"] = enh_age_freq[\"count_ids\"].sum()\n",
    "    enh_age_freq[\"frac_of_total\"] = enh_age_freq[\"count_ids\"].divide(enh_age_freq.totals).round(3) # get fraction of total\n",
    "\n",
    "    simple_total = enh_age_freq[\"count_ids\"].loc[enh_age_freq.core_remodeling==0].sum()\n",
    "\n",
    "    enh_age_freq[\"frac_of_arch\"] = enh_age_freq[\"count_ids\"].divide(simple_total).round(3) # get fraction of simple\n",
    "\n",
    "    complex_total = enh_age_freq[\"count_ids\"].loc[enh_age_freq.core_remodeling==1].sum()\n",
    "    enh_age_freq[\"frac_of_arch\"].loc[enh_age_freq.core_remodeling == 1] = enh_age_freq[\"count_ids\"].divide(complex_total).round(3) # get fraction of complex enhancers\n",
    "\n",
    "    enh_age_freq[\"total_freq\"]= 1\n",
    "    enh_age_freq = pd.merge(enh_age_freq, syn_gen_bkgd[[\"mrca_2\", \"taxon2\"]], how = \"left\", on = \"mrca_2\").drop_duplicates()\n",
    "\n",
    "    enh_age_freq[\"dataset\"] = dataset\n",
    "    enh_age_freq[\"sid\"] = sid\n",
    "\n",
    "    write_dict[\"enh_age_freq\"] = enh_age_freq\n",
    "    enh_age_freq.to_csv(\"%s%s-enh_age_freq.tsv\" % (outpath, sid), sep = '\\t', header= True, index = False)\n",
    "    \n",
    "\n",
    "    ### Syn freq ###\n",
    "    # group by syn age & architecture\n",
    "    syn_arch= df.groupby([\"mrca_2\", \"code\"])[\"syn_id\"].count().reset_index() \n",
    "\n",
    "    # group by architecture\n",
    "    syn_totals = syn_arch.groupby([\"code\"])[\"syn_id\"].sum().reset_index()\n",
    "    syn_totals.columns = [\"code\", \"total_count\"]\n",
    "\n",
    "    # calculate age v. architecture\n",
    "    syn_arch = pd.merge(syn_arch, syn_totals, how = \"left\", on = \"code\")\n",
    "    syn_arch[\"frequency\"] = syn_arch[\"syn_id\"].divide(syn_arch[\"total_count\"])\n",
    "    syn_arch[\"dataset\"] = dataset\n",
    "\n",
    "    ### df_empty ### add in empty data\n",
    "    df_empty = pd.DataFrame({'code':[\"derived\", \"derived\", \"complex_core\", \"complex_core\"],\n",
    "     'syn_id':[0, 0, 0, 0],\n",
    "     'total_count':[0, 0, 0, 0],\n",
    "     'frequency':[0, 0, 0, 0],\n",
    "     'dataset':[\"ROADMAP\", \"shuffle\", \"ROADMAP\", \"shuffle\"],\n",
    "     'mrca_2':[0.957, 0.957, 0.000, 0.000],\n",
    "     'taxon2':[\"Vertebrata\", \"Vertebrata\", \"Homo\", \"Homo\"]})\n",
    "\n",
    "    syn_arch = syn_arch.append(df_empty, ignore_index=True)\n",
    "    syn_arch[\"code2\"] = syn_arch[\"code\"] + \"-\"+ syn_arch[\"dataset\"]\n",
    "    syn_arch[\"sid\"]= sid\n",
    "    write_dict[\"syn_age_freq\"] = syn_arch\n",
    "    syn_arch.to_csv(\"%s%s-syn_age_freq.tsv\" % (outpath, sid) , sep = '\\t', header= True, index = False)\n",
    "\n",
    "    return write_dict\n",
    "#    return desc_all, desc_arch, syn_lens, lin_regression, breaks_freq, breaks_mrca,  enh_age_freq ,syn_arch\n",
    "def main(argv):\n",
    "    syn_gen_bkgd_file = \"/dors/capra_lab/projects/enhancer_ages/hg19_syn_gen_bkgd.tsv\"\n",
    "    syn_gen_bkgd = pd.read_csv(syn_gen_bkgd_file, sep = '\\t')\n",
    "    syn_gen_bkgd[\"mrca\"]=syn_gen_bkgd[\"mrca\"].round(3)\n",
    "    syn_gen_bkgd[\"mrca_2\"]=syn_gen_bkgd[\"mrca_2\"].round(3)\n",
    "    syn_gen_bkgd = syn_gen_bkgd[[\"mrca\", \"taxon\", \"mrca_2\", \"taxon2\"]]\n",
    "\n",
    "    desc_file = \"/dors/capra_lab/projects/enhancer_ages/roadmap_encode/data/hg19_roadmap_samples_enh_age/roadmap_hg19_sample_id_desc.csv\"\n",
    "    desc_df = pd.read_csv(desc_file, header = None)\n",
    "\n",
    "    df = pd.read_csv(F, sep='\\t', header = None, low_memory=False)\n",
    "\n",
    "    formatted_df = format_df(df, SAMPLE_ID, SAMPLE_TEN_PERCENT, LEN_CUTOFF, syn_gen_bkgd, OUTPATH)\n",
    "\n",
    "    statsdf = get_data_stats(formatted_df, SAMPLE_ID, \"SHUFFLE\", OUTPATH, syn_gen_bkgd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr_syn</th>\n",
       "      <th>start_syn</th>\n",
       "      <th>end_syn</th>\n",
       "      <th>enh_id</th>\n",
       "      <th>chr_enh</th>\n",
       "      <th>start_enh</th>\n",
       "      <th>end_enh</th>\n",
       "      <th>seg_index</th>\n",
       "      <th>core_remodeling</th>\n",
       "      <th>core</th>\n",
       "      <th>...</th>\n",
       "      <th>sid</th>\n",
       "      <th>enh_len</th>\n",
       "      <th>syn_len</th>\n",
       "      <th>seg_rep</th>\n",
       "      <th>syn_id</th>\n",
       "      <th>code</th>\n",
       "      <th>arch</th>\n",
       "      <th>taxon</th>\n",
       "      <th>mrca_2</th>\n",
       "      <th>taxon2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>100045397</td>\n",
       "      <td>100045647</td>\n",
       "      <td>chr1:100045397-100045647</td>\n",
       "      <td>chr1</td>\n",
       "      <td>100045397</td>\n",
       "      <td>100045647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>E098_x_ucsc_tfbs_midpeak</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>chr1:100045397-100045647</td>\n",
       "      <td>simple</td>\n",
       "      <td>simple</td>\n",
       "      <td>Theria</td>\n",
       "      <td>0.308</td>\n",
       "      <td>Theria (159)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>100114933</td>\n",
       "      <td>100115489</td>\n",
       "      <td>chr1:100114933-100116442</td>\n",
       "      <td>chr1</td>\n",
       "      <td>100114933</td>\n",
       "      <td>100116442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>E098_x_ucsc_tfbs_midpeak</td>\n",
       "      <td>1509</td>\n",
       "      <td>556</td>\n",
       "      <td>0.368456</td>\n",
       "      <td>chr1:100114933-100115489</td>\n",
       "      <td>complex_core</td>\n",
       "      <td>complexenh</td>\n",
       "      <td>Theria</td>\n",
       "      <td>0.308</td>\n",
       "      <td>Theria (159)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>100115489</td>\n",
       "      <td>100116259</td>\n",
       "      <td>chr1:100114933-100116442</td>\n",
       "      <td>chr1</td>\n",
       "      <td>100114933</td>\n",
       "      <td>100116442</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>E098_x_ucsc_tfbs_midpeak</td>\n",
       "      <td>1509</td>\n",
       "      <td>770</td>\n",
       "      <td>0.510272</td>\n",
       "      <td>chr1:100115489-100116259</td>\n",
       "      <td>derived</td>\n",
       "      <td>complexenh</td>\n",
       "      <td>Eutheria</td>\n",
       "      <td>0.175</td>\n",
       "      <td>Eutheria (105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr1</td>\n",
       "      <td>100116259</td>\n",
       "      <td>100116442</td>\n",
       "      <td>chr1:100114933-100116442</td>\n",
       "      <td>chr1</td>\n",
       "      <td>100114933</td>\n",
       "      <td>100116442</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>E098_x_ucsc_tfbs_midpeak</td>\n",
       "      <td>1509</td>\n",
       "      <td>183</td>\n",
       "      <td>0.121272</td>\n",
       "      <td>chr1:100116259-100116442</td>\n",
       "      <td>complex_core</td>\n",
       "      <td>complexenh</td>\n",
       "      <td>Theria</td>\n",
       "      <td>0.308</td>\n",
       "      <td>Theria (159)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr1</td>\n",
       "      <td>100153285</td>\n",
       "      <td>100153680</td>\n",
       "      <td>chr1:100153285-100153680</td>\n",
       "      <td>chr1</td>\n",
       "      <td>100153285</td>\n",
       "      <td>100153680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>E098_x_ucsc_tfbs_midpeak</td>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>chr1:100153285-100153680</td>\n",
       "      <td>simple</td>\n",
       "      <td>simple</td>\n",
       "      <td>Eutheria</td>\n",
       "      <td>0.175</td>\n",
       "      <td>Eutheria (105)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr_syn  start_syn    end_syn                    enh_id chr_enh  start_enh  \\\n",
       "0    chr1  100045397  100045647  chr1:100045397-100045647    chr1  100045397   \n",
       "4    chr1  100114933  100115489  chr1:100114933-100116442    chr1  100114933   \n",
       "5    chr1  100115489  100116259  chr1:100114933-100116442    chr1  100114933   \n",
       "6    chr1  100116259  100116442  chr1:100114933-100116442    chr1  100114933   \n",
       "7    chr1  100153285  100153680  chr1:100153285-100153680    chr1  100153285   \n",
       "\n",
       "     end_enh  seg_index  core_remodeling  core  ...                       sid  \\\n",
       "0  100045647          1                0     1  ...  E098_x_ucsc_tfbs_midpeak   \n",
       "4  100116442          1                1     1  ...  E098_x_ucsc_tfbs_midpeak   \n",
       "5  100116442          2                1     0  ...  E098_x_ucsc_tfbs_midpeak   \n",
       "6  100116442          3                1     1  ...  E098_x_ucsc_tfbs_midpeak   \n",
       "7  100153680          1                0     1  ...  E098_x_ucsc_tfbs_midpeak   \n",
       "\n",
       "  enh_len  syn_len   seg_rep                    syn_id          code  \\\n",
       "0     250      250  1.000000  chr1:100045397-100045647        simple   \n",
       "4    1509      556  0.368456  chr1:100114933-100115489  complex_core   \n",
       "5    1509      770  0.510272  chr1:100115489-100116259       derived   \n",
       "6    1509      183  0.121272  chr1:100116259-100116442  complex_core   \n",
       "7     395      395  1.000000  chr1:100153285-100153680        simple   \n",
       "\n",
       "         arch     taxon mrca_2          taxon2  \n",
       "0      simple    Theria  0.308    Theria (159)  \n",
       "4  complexenh    Theria  0.308    Theria (159)  \n",
       "5  complexenh  Eutheria  0.175  Eutheria (105)  \n",
       "6  complexenh    Theria  0.308    Theria (159)  \n",
       "7      simple  Eutheria  0.175  Eutheria (105)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = \"E098\"\n",
    "dataset = \"x\"\n",
    "formatted_df[\"mrca\"] = formatted_df[\"mrca\"].round(3)\n",
    "formatted_df[\"mrca_2\"] = formatted_df[\"mrca_2\"].round(3)\n",
    "statsdf = get_data_stats(formatted_df, SAMPLE_ID, \"SHUFFLE\", OUTPATH, syn_gen_bkgd)\n",
    "formatted_df_all = formatted_df.groupby(\"core_remodeling\").describe().reset_index() # groupby simple and complex and get basic stats\n",
    "\n",
    "formatted_df_all_ = pd.melt(formatted_df_all, id_vars=['core_remodeling'], value_vars=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "formatted_df_all_.columns = [\"core_remodeling\", \"len_cat\", \"len_stat\", \"x\"]\n",
    "\n",
    "formatted_df_all_[\"sid\"] = sid\n",
    "formatted_df_all_[\"dataset\"] = dataset\n",
    "\n",
    "#write_dict[\"enh_len_stats\"] = formatted_df_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BASIC', 'enh_len_stats', 'enh_arch_len_stats', 'syn_len_stats', 'linear_regression', 'break_freq', 'breaks_mrca', 'enh_age_freq', 'syn_age_freq'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsdf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(statsdf[\"BASIC\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfenv)",
   "language": "python",
   "name": "sfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
